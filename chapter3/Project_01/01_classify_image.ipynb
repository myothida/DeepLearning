{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "## Image Classification Using Known CNN Models\n",
    "\n",
    "### Overview\n",
    "\n",
    "In this project, we classify images using five well-known Convolutional Neural Network (CNN) models implemented with the Python `keras` library. The models used are `ResNet50`, `VGG16`, `InceptionV3`, `Xception`, and `EfficientNetB7`. The goal is to load an image, pass it through each of these models, and obtain the top prediction for the image. This project consists of two Python scripts: one for defining the CNN models (`cnn_models.py`) and one main script (`main.py`) for classifying an image.\n",
    "\n",
    "### Project Components\n",
    "\n",
    "#### 1. `cnn_models.py`\n",
    "\n",
    "This script defines a class, `cnnModels`, which provides an interface to load and use the pre-trained CNN models. The class includes methods for initializing models, retrieving models by name, and classifying images.\n",
    "\n",
    "##### `cnnModels` Class\n",
    "\n",
    "- **`__init__(self)`**: Initializes the class and loads the pre-trained models.\n",
    "- **`resnet(self)`**: Loads and returns the `ResNet50` model with ImageNet weights.\n",
    "- **`vggnet(self)`**: Loads and returns the `VGG16` model with ImageNet weights.\n",
    "- **`inception(self)`**: Loads and returns the `InceptionV3` model with ImageNet weights.\n",
    "- **`convnet(self)`**: Loads and returns the `Xception` model with ImageNet weights.\n",
    "- **`efficientnet(self)`**: Loads and returns the `EfficientNetB7` model with ImageNet weights.\n",
    "- **`get_model(self, name)`**: Retrieves a model by name from the dictionary of models.\n",
    "- **`classify_image(self, name, img)`**: Classifies an image using the specified model and returns the top 3 predictions.\n",
    "\n",
    "#### 2. `main.ipynb`\n",
    "\n",
    "This script demonstrates how to use the `cnnModels` class to classify an image.\n",
    "\n",
    "##### Example Usage\n",
    "\n",
    "```python\n",
    "from cnn_models import cnnModels\n",
    "from keras.preprocessing.image import load_img\n",
    "\n",
    "# Specify the image path\n",
    "img_path = './imgs/dog.jpeg'\n",
    "img = load_img(img_path)\n",
    "\n",
    "# Initialize the cnnModels class\n",
    "model = cnnModels()\n",
    "\n",
    "# Classify the image using ResNet50\n",
    "preds1 = model.classify_image('ResNet50', img)\n",
    "\n",
    "# Print the top predictions\n",
    "for pred in preds1:\n",
    "    print(f\"{pred[1]}: {pred[2]}, {pred[3]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 770ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001C69DA29300> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Class</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ResNet50</td>\n",
       "      <td>tennis_ball</td>\n",
       "      <td>0.918862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VGGNet16</td>\n",
       "      <td>golden_retriever</td>\n",
       "      <td>0.570092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>InceptionV3</td>\n",
       "      <td>flatworm</td>\n",
       "      <td>0.927169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ConvNeXt</td>\n",
       "      <td>ping-pong_ball</td>\n",
       "      <td>0.486053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EfficientNet</td>\n",
       "      <td>golden_retriever</td>\n",
       "      <td>0.603915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model             Class  Probability\n",
       "0      ResNet50       tennis_ball     0.918862\n",
       "1      VGGNet16  golden_retriever     0.570092\n",
       "2   InceptionV3          flatworm     0.927169\n",
       "3      ConvNeXt    ping-pong_ball     0.486053\n",
       "4  EfficientNet  golden_retriever     0.603915"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cnn_models\n",
    "import pandas as pd\n",
    "from keras.utils import load_img  #type: ignore\n",
    "\n",
    "\n",
    "# Specify the image path\n",
    "img_path = './imgs/dog.jpeg'\n",
    "img = load_img(img_path)\n",
    "\n",
    "model = cnn_models.cnnModels()\n",
    "model_name = ['ResNet50', 'VGGNet16', 'InceptionV3', 'ConvNeXt', 'EfficientNet']\n",
    "flat_preds = []\n",
    "\n",
    "for name in model_name:\n",
    "    preds = model.classify_image(name, img)\n",
    "    flat_preds.extend([item for sublist in preds for item in sublist])\n",
    "\n",
    "\n",
    "df_flat_preds = pd.DataFrame(flat_preds, columns=['model', 'Class', 'Probability'])\n",
    "df_flat_preds['model']= model_name\n",
    "df_flat_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The state-of-the-art CNN models are tested using two datasets: \n",
    "1) AI-generated Images that contains 10 images\n",
    "2) 10 Real Images collected from the internet\n",
    "\n",
    "average accuracy, precision and recall scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>model</th>\n",
       "      <th>Class</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [label, model, Class, Probability]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "fake_dir = './dataset/synthetic/'\n",
    "real_dir = './dataset/real/'\n",
    "\n",
    "model = cnn_models.cnnModels()\n",
    "model_name = ['ResNet50', 'VGGNet16', 'InceptionV3', 'ConvNeXt', 'EfficientNet']\n",
    "\n",
    "def get_image_paths(image_dir):\n",
    "    image_paths = []\n",
    "    labels =[]\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.endswith('.jpeg') or filename.endswith('.png'):\n",
    "            image_path = os.path.join(image_dir, filename)\n",
    "            image_paths.append(image_path)\n",
    "            labels.append(filename.split('.')[0])\n",
    "    return image_paths, labels\n",
    "\n",
    "image_paths, labels = get_image_paths(fake_dir)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flat_preds = pd.DataFrame(columns=['label', 'model', 'Class', 'Probability'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880ms/step\n",
      "[('n03930313', 'picket_fence', 0.7755485)]\n"
     ]
    }
   ],
   "source": [
    "img = load_img(img_path) \n",
    "preds = model.classify_image(name, img)\n",
    "print(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 827ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 884ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('n04482393', 'tricycle', 0.8468541),\n",
       " ('n03944341', 'pinwheel', 0.6991526),\n",
       " ('n03944341', 'pinwheel', 0.49099445),\n",
       " ('n03642806', 'laptop', 0.39526895),\n",
       " ('n01514859', 'hen', 0.50244856),\n",
       " ('n04409515', 'tennis_ball', 0.9188617),\n",
       " ('n09193705', 'alp', 0.37877044),\n",
       " ('n04522168', 'vase', 0.1603659),\n",
       " ('n02782093', 'balloon', 0.09864314),\n",
       " ('n03930313', 'picket_fence', 0.99313366),\n",
       " ('n04482393', 'tricycle', 0.19207753),\n",
       " ('n01910747', 'jellyfish', 0.1741677),\n",
       " ('n09229709', 'bubble', 0.22225265),\n",
       " ('n02123045', 'tabby', 0.20779778),\n",
       " ('n01514668', 'cock', 0.67628247),\n",
       " ('n02099601', 'golden_retriever', 0.57009184),\n",
       " ('n02389026', 'sorrel', 0.21419549),\n",
       " ('n03991062', 'pot', 0.3724951),\n",
       " ('n02120079', 'Arctic_fox', 0.15921089),\n",
       " ('n02782093', 'balloon', 0.29854703),\n",
       " ('n03047690', 'clog', 0.5929041),\n",
       " ('n01924916', 'flatworm', 0.9999999),\n",
       " ('n01924916', 'flatworm', 0.89688516),\n",
       " ('n06359193', 'web_site', 1.0),\n",
       " ('n04328186', 'stopwatch', 0.58571535),\n",
       " ('n01924916', 'flatworm', 0.9271688),\n",
       " ('n01924916', 'flatworm', 0.9859701),\n",
       " ('n06359193', 'web_site', 0.79714996),\n",
       " ('n03047690', 'clog', 0.99435955),\n",
       " ('n01924916', 'flatworm', 0.9999573),\n",
       " ('n03942813', 'ping-pong_ball', 0.9837646),\n",
       " ('n03942813', 'ping-pong_ball', 0.9999999),\n",
       " ('n03942813', 'ping-pong_ball', 0.99986124),\n",
       " ('n03942813', 'ping-pong_ball', 0.9999999),\n",
       " ('n03942813', 'ping-pong_ball', 0.99993),\n",
       " ('n03942813', 'ping-pong_ball', 0.4860531),\n",
       " ('n03942813', 'ping-pong_ball', 0.99911326),\n",
       " ('n03942813', 'ping-pong_ball', 0.96129555),\n",
       " ('n03942813', 'ping-pong_ball', 0.9999819),\n",
       " ('n03942813', 'ping-pong_ball', 0.9990926),\n",
       " ('n04482393', 'tricycle', 0.81798655),\n",
       " ('n01828970', 'bee_eater', 0.3535776),\n",
       " ('n02264363', 'lacewing', 0.64868724),\n",
       " ('n02123394', 'Persian_cat', 0.49992585),\n",
       " ('n01514859', 'hen', 0.6226044),\n",
       " ('n02099601', 'golden_retriever', 0.6039146),\n",
       " ('n09193705', 'alp', 0.3835706),\n",
       " ('n03065424', 'coil', 0.14973381),\n",
       " ('n02120079', 'Arctic_fox', 0.1484544),\n",
       " ('n03930313', 'picket_fence', 0.7755485)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_preds = []\n",
    "for name in model_name:    \n",
    "    for img_path in image_paths:\n",
    "        img = load_img(img_path) \n",
    "        preds = model.classify_image(name, img)\n",
    "        print(preds)\n",
    "        flat_preds.extend([item for sublist in preds for item in sublist])    \n",
    "   \n",
    "flat_preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('n03930313', 'picket_fence', 0.99313366),\n",
       " ('n02782093', 'balloon', 0.29854703),\n",
       " ('n01924916', 'flatworm', 0.9999573),\n",
       " ('n03942813', 'ping-pong_ball', 0.9990926),\n",
       " ('n03930313', 'picket_fence', 0.7755485)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_flat_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
