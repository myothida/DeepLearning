{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "## Image Classification Using Known CNN Models\n",
    "\n",
    "### Overview\n",
    "\n",
    "In this project, we classify images using five well-known Convolutional Neural Network (CNN) models implemented with the Python `keras` library. The models used are `ResNet50`, `VGG16`, `InceptionV3`, `Xception`, and `EfficientNetB7`. The goal is to load an image, pass it through each of these models, and obtain the top prediction for the image. This project consists of two Python scripts: one for defining the CNN models (`cnn_models.py`) and one main script (`main.py`) for classifying an image.\n",
    "\n",
    "### Project Components\n",
    "\n",
    "#### 1. `cnn_models.py`\n",
    "\n",
    "This script defines a class, `cnnModels`, which provides an interface to load and use the pre-trained CNN models. The class includes methods for initializing models, retrieving models by name, and classifying images.\n",
    "\n",
    "##### `cnnModels` Class\n",
    "\n",
    "- **`__init__(self)`**: Initializes the class and loads the pre-trained models.\n",
    "- **`resnet(self)`**: Loads and returns the `ResNet50` model with ImageNet weights.\n",
    "- **`vggnet(self)`**: Loads and returns the `VGG16` model with ImageNet weights.\n",
    "- **`inception(self)`**: Loads and returns the `InceptionV3` model with ImageNet weights.\n",
    "- **`convnet(self)`**: Loads and returns the `Xception` model with ImageNet weights.\n",
    "- **`efficientnet(self)`**: Loads and returns the `EfficientNetB7` model with ImageNet weights.\n",
    "- **`get_model(self, name)`**: Retrieves a model by name from the dictionary of models.\n",
    "- **`classify_image(self, name, img)`**: Classifies an image using the specified model and returns the top 3 predictions.\n",
    "\n",
    "#### 2. `main.ipynb`\n",
    "\n",
    "This script demonstrates how to use the `cnnModels` class to classify an image.\n",
    "\n",
    "##### Example Usage\n",
    "\n",
    "```python\n",
    "from cnn_models import cnnModels\n",
    "from keras.preprocessing.image import load_img\n",
    "\n",
    "# Specify the image path\n",
    "img_path = './imgs/dog.jpeg'\n",
    "img = load_img(img_path)\n",
    "\n",
    "# Initialize the cnnModels class\n",
    "model = cnnModels()\n",
    "\n",
    "# Classify the image using ResNet50\n",
    "preds1 = model.classify_image('ResNet50', img)\n",
    "\n",
    "# Print the top predictions\n",
    "for pred in preds1:\n",
    "    print(f\"{pred[1]}: {pred[2]}, {pred[3]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The state-of-the-art CNN models are tested using two datasets: \n",
    "1) AI-generated Images that contains 10 images\n",
    "2) 10 Real Images collected from the internet\n",
    "\n",
    "average accuracy, precision and recall scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cnn_models\n",
    "import pandas as pd\n",
    "from keras.utils import load_img #type: ignore\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(image_dir):\n",
    "    model = cnn_models.cnnModels()\n",
    "    model_name = ['ResNet50', 'VGGNet16', 'InceptionV3', 'ConvNeXt', 'EfficientNet']\n",
    "    result_df = pd.DataFrame(columns = model_name + [name + '_prob' for name in model_name])\n",
    "\n",
    "    labels =[]    \n",
    "    row_values = []\n",
    "\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.endswith('.jpeg') or filename.endswith('.png')or filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(image_dir, filename)\n",
    "            img = load_img(image_path)   \n",
    "            labels.append(filename.split('.')[0])\n",
    "            prob_preds = []\n",
    "            class_preds = []\n",
    "            for name in model_name:\n",
    "                preds = model.classify_image(name, img)[0][0][1:3]\n",
    "                class_preds.append(preds[0])\n",
    "                prob_preds.append(preds[1])\n",
    "            \n",
    "            row_values.append(class_preds + prob_preds)\n",
    "    \n",
    "    result_df = pd.DataFrame(row_values, columns = model_name + [name + '_prob' for name in model_name]) \n",
    "    result_df['label'] = labels        \n",
    "    \n",
    "    return result_df\n",
    "\n",
    "fake_dir = './dataset/synthetic/'\n",
    "real_dir = './dataset/real/'\n",
    "    \n",
    "real_result = get_predictions(real_dir)\n",
    "fake_result = get_predictions(fake_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_result.to_csv('./results/real_result.csv', index = False)\n",
    "fake_result.to_csv('./results/fake_result.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResNet50</th>\n",
       "      <th>VGGNet16</th>\n",
       "      <th>InceptionV3</th>\n",
       "      <th>ConvNeXt</th>\n",
       "      <th>EfficientNet</th>\n",
       "      <th>ResNet50_prob</th>\n",
       "      <th>VGGNet16_prob</th>\n",
       "      <th>InceptionV3_prob</th>\n",
       "      <th>ConvNeXt_prob</th>\n",
       "      <th>EfficientNet_prob</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>moped</td>\n",
       "      <td>moped</td>\n",
       "      <td>stopwatch</td>\n",
       "      <td>moped</td>\n",
       "      <td>moped</td>\n",
       "      <td>0.805327</td>\n",
       "      <td>0.424188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.827512</td>\n",
       "      <td>0.650366</td>\n",
       "      <td>bike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bee_eater</td>\n",
       "      <td>house_finch</td>\n",
       "      <td>web_site</td>\n",
       "      <td>bee_eater</td>\n",
       "      <td>bee_eater</td>\n",
       "      <td>0.529495</td>\n",
       "      <td>0.962029</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.926593</td>\n",
       "      <td>0.733849</td>\n",
       "      <td>bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cabbage_butterfly</td>\n",
       "      <td>cabbage_butterfly</td>\n",
       "      <td>web_site</td>\n",
       "      <td>ringlet</td>\n",
       "      <td>ringlet</td>\n",
       "      <td>0.606160</td>\n",
       "      <td>0.772593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.926650</td>\n",
       "      <td>0.756958</td>\n",
       "      <td>butterfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tabby</td>\n",
       "      <td>tabby</td>\n",
       "      <td>web_site</td>\n",
       "      <td>Egyptian_cat</td>\n",
       "      <td>Egyptian_cat</td>\n",
       "      <td>0.651294</td>\n",
       "      <td>0.480646</td>\n",
       "      <td>0.999809</td>\n",
       "      <td>0.779567</td>\n",
       "      <td>0.459261</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hen</td>\n",
       "      <td>hen</td>\n",
       "      <td>pencil_sharpener</td>\n",
       "      <td>hen</td>\n",
       "      <td>hen</td>\n",
       "      <td>0.990856</td>\n",
       "      <td>0.961262</td>\n",
       "      <td>0.858182</td>\n",
       "      <td>0.889114</td>\n",
       "      <td>0.697963</td>\n",
       "      <td>chicken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wire-haired_fox_terrier</td>\n",
       "      <td>German_shepherd</td>\n",
       "      <td>web_site</td>\n",
       "      <td>toy_terrier</td>\n",
       "      <td>kelpie</td>\n",
       "      <td>0.167907</td>\n",
       "      <td>0.148021</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.474873</td>\n",
       "      <td>0.305305</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tray</td>\n",
       "      <td>pitcher</td>\n",
       "      <td>clog</td>\n",
       "      <td>hair_slide</td>\n",
       "      <td>lampshade</td>\n",
       "      <td>0.416434</td>\n",
       "      <td>0.140679</td>\n",
       "      <td>0.860016</td>\n",
       "      <td>0.291826</td>\n",
       "      <td>0.491164</td>\n",
       "      <td>flower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hartebeest</td>\n",
       "      <td>hartebeest</td>\n",
       "      <td>vase</td>\n",
       "      <td>sorrel</td>\n",
       "      <td>hartebeest</td>\n",
       "      <td>0.494828</td>\n",
       "      <td>0.875766</td>\n",
       "      <td>0.473370</td>\n",
       "      <td>0.256203</td>\n",
       "      <td>0.627339</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ram</td>\n",
       "      <td>ram</td>\n",
       "      <td>web_site</td>\n",
       "      <td>hog</td>\n",
       "      <td>ram</td>\n",
       "      <td>0.759179</td>\n",
       "      <td>0.723133</td>\n",
       "      <td>0.856891</td>\n",
       "      <td>0.765434</td>\n",
       "      <td>0.411331</td>\n",
       "      <td>sheep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sombrero</td>\n",
       "      <td>ice_lolly</td>\n",
       "      <td>saltshaker</td>\n",
       "      <td>tennis_ball</td>\n",
       "      <td>sombrero</td>\n",
       "      <td>0.640533</td>\n",
       "      <td>0.069819</td>\n",
       "      <td>0.999474</td>\n",
       "      <td>0.321509</td>\n",
       "      <td>0.143886</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ResNet50           VGGNet16       InceptionV3      ConvNeXt  \\\n",
       "0                    moped              moped         stopwatch         moped   \n",
       "1                bee_eater        house_finch          web_site     bee_eater   \n",
       "2        cabbage_butterfly  cabbage_butterfly          web_site       ringlet   \n",
       "3                    tabby              tabby          web_site  Egyptian_cat   \n",
       "4                      hen                hen  pencil_sharpener           hen   \n",
       "5  wire-haired_fox_terrier    German_shepherd          web_site   toy_terrier   \n",
       "6                     tray            pitcher              clog    hair_slide   \n",
       "7               hartebeest         hartebeest              vase        sorrel   \n",
       "8                      ram                ram          web_site           hog   \n",
       "9                 sombrero          ice_lolly        saltshaker   tennis_ball   \n",
       "\n",
       "   EfficientNet  ResNet50_prob  VGGNet16_prob  InceptionV3_prob  \\\n",
       "0         moped       0.805327       0.424188          1.000000   \n",
       "1     bee_eater       0.529495       0.962029          1.000000   \n",
       "2       ringlet       0.606160       0.772593          1.000000   \n",
       "3  Egyptian_cat       0.651294       0.480646          0.999809   \n",
       "4           hen       0.990856       0.961262          0.858182   \n",
       "5        kelpie       0.167907       0.148021          0.999979   \n",
       "6     lampshade       0.416434       0.140679          0.860016   \n",
       "7    hartebeest       0.494828       0.875766          0.473370   \n",
       "8           ram       0.759179       0.723133          0.856891   \n",
       "9      sombrero       0.640533       0.069819          0.999474   \n",
       "\n",
       "   ConvNeXt_prob  EfficientNet_prob      label  \n",
       "0       0.827512           0.650366       bike  \n",
       "1       0.926593           0.733849       bird  \n",
       "2       0.926650           0.756958  butterfly  \n",
       "3       0.779567           0.459261        cat  \n",
       "4       0.889114           0.697963    chicken  \n",
       "5       0.474873           0.305305        dog  \n",
       "6       0.291826           0.491164     flower  \n",
       "7       0.256203           0.627339      horse  \n",
       "8       0.765434           0.411331      sheep  \n",
       "9       0.321509           0.143886      woman  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of CNN Performance on Real and Synthetic Images\n",
    "Figures 1 and 2 present the results of testing five state-of-the-art Convolutional Neural Networks (CNNs) on 10 real and 10 synthetic images. The analysis indicates the following key points:\n",
    "\n",
    "General Performance:\n",
    "\n",
    "Real vs. AI-Generated Images: All models perform better in recognizing real images compared to AI-generated images. This suggests that state-of-the-art CNN models might be better trained or more suited to recognizing features present in real images.\n",
    "Model-Specific Observations:\n",
    "\n",
    "ConvNeXt and EfficientNet: These models show relatively better performance compared to the others. This implies that ConvNeXt and EfficientNet may be more robust or have better generalization capabilities for this particular task.\n",
    "InceptionV3: Despite its low accuracy, InceptionV3 demonstrates very high confidence in its predictions. This indicates potential overconfidence or issues with calibration, meaning it might be making incorrect predictions with high certainty.\n",
    "Limitations of Evaluation:\n",
    "\n",
    "General Evaluation: The current evaluation is broad and does not delve into specific performance metrics (e.g., precision, recall, F1-score) for each model. Detailed metrics are crucial for a thorough assessment.\n",
    "Limited Dataset: The test dataset is limited to 20 images (10 real and 10 synthetic), which means the results might not be representative of broader performance. This limitation could lead to overfitting on this specific dataset and might not capture the full variability of possible images.\n",
    "Recommendations for Further Analysis:\n",
    "\n",
    "Detailed Metrics Calculation: Calculate detailed metrics such as accuracy, precision, recall, F1-score, ROC-AUC, and average precision for each model to provide a comprehensive evaluation.\n",
    "Dataset Expansion: Use a larger and more diverse test dataset to ensure robustness and generalizability of the models. This dataset should include a wide range of real and synthetic images, covering various edge cases and difficult examples.\n",
    "Model Calibration: Investigate and potentially recalibrate models like InceptionV3 to align their confidence scores with actual performance. Techniques such as Platt scaling or isotonic regression can be used for calibration.\n",
    "Error Analysis: Perform a detailed error analysis to identify common failure modes for each model and understand whether certain types of images (e.g., specific classes, image qualities) are consistently misclassified.\n",
    "Conclusion\n",
    "While ConvNeXt and EfficientNet demonstrate promising results, the general nature of the evaluation and the limited dataset highlight the need for more comprehensive testing and analysis. Addressing these limitations will provide a clearer understanding of each model's strengths and areas for improvement, leading to more reliable and effective deployment in real-world scenarios.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
