{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection. \n",
    "The dataset includes detailed information on resale transactions of HDB flats between January 1, 2017, and March 30, 2024. The dataset contains 180,154 rows and 11 columns and was downloaded on May 23, 2024. \n",
    "\n",
    "**Dataset URL**: [HDB Resale Prices](https://beta.data.gov.sg/datasets/d_8b84c4ee58e3cfc0ece0d773c8ca6abc/view) \n",
    "**HDB RPI URL**:[HDB Resale Prices Index](https://www.hdb.gov.sg/residential/selling-a-flat/overview/resale-statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import data_config as cfg\n",
    "\n",
    "df_raw = pd.read_csv('../data/SGHDB2017-2024.csv')\n",
    "cfg.save_dataset_info(df_raw, fname='dataset_info.csv')\n",
    "\n",
    "df = cfg.adjust_resale_price(df_raw, cut_off_date='2024-04-01')\n",
    "cfg.visualize_adjusted_price(df[['month', 'resale_price', 'adjusted_price']].copy(), fname='adjusted_price.png')\n",
    "\n",
    "df_clean = cfg.preprocess_data(df)\n",
    "print(df_raw.shape, df.shape, df_clean.shape)\n",
    "df_clean.to_csv('../data/SGHDB2017-2024_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Install Required Libraries: \n",
    "Ensure you have the necessary libraries installed. You can install them using pip if they are not already installed.\n",
    "```sgh \n",
    "pip install tensorflow pandas scikit-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Load and Prepare the Data:\n",
    "Load your dataset and prepare it for training. This includes splitting it into training and testing sets and normalizing the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def create_regression_model(input_shape, params={}):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(shape=input_shape),    \n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(16, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the data\n",
    "df = pd.read_csv('../data/SGHDB2017-2024_clean.csv')\n",
    "y = df['adjusted_price'].values   # Target\n",
    "X = df.drop(columns = 'adjusted_price')  # Features\n",
    "\n",
    "# Step 2: Prepare the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize continuous features\n",
    "continuous_columns = ['flat_type', 'floor_area_sqm',  'floor', 'remaining_lease_months']\n",
    "binary_columns = df.columns.difference(continuous_columns + ['adjusted_price']).tolist()\n",
    "scaler = StandardScaler()\n",
    "X_train_continuous = scaler.fit_transform(X_train[continuous_columns])\n",
    "X_test_continuous = scaler.transform(X_test[continuous_columns])\n",
    "\n",
    "# Combine scaled continuous features and binary features\n",
    "X_train = np.hstack([X_train_continuous, X_train[binary_columns].values])\n",
    "X_test = np.hstack([X_test_continuous, X_test[binary_columns].values])\n",
    "\n",
    "# Step 3: Create and train the model\n",
    "model = create_regression_model(input_shape=[X_train.shape[1]])\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, \n",
    "                    validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_predictions(y_actual, y_predicted):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_actual, y_predicted, color='blue')\n",
    "    plt.xlabel('Actual value')\n",
    "    plt.ylabel('Predicted value')\n",
    "    plt.title('Predicted vs Actual')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Evaluate the model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "df_results = pd.DataFrame(columns=['Train', 'Test'])\n",
    "\n",
    "y_pred = model.predict(X_train)\n",
    "df_results.loc['Root Mean Squared Error', 'Train'] = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "df_results.loc['Mean Aboslute Error', 'Train'] = mean_absolute_error(y_train, y_pred)\n",
    "df_results.loc['Mean Aboslute Percentage Error', 'Train'] = mean_absolute_percentage_error(y_train, y_pred)*100\n",
    "df_results.loc['R2 score', 'Train'] = r2_score(y_train, y_pred)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "df_results.loc['Root Mean Squared Error', 'Test'] = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "df_results.loc['Mean Aboslute Error', 'Test'] = mean_absolute_error(y_test, y_pred)\n",
    "df_results.loc['Mean Aboslute Percentage Error', 'Test'] = mean_absolute_percentage_error(y_test, y_pred)*100\n",
    "df_results.loc['R2 score', 'Test'] = r2_score(y_test, y_pred)\n",
    "\n",
    "df_results = df_results.astype('Float64').round(2)\n",
    "df_results.to_csv('../data/model_evaluation.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
